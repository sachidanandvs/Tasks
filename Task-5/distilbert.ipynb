{"nbformat":4,"nbformat_minor":5,"metadata":{"accelerator":"GPU","colab":{"name":"copy.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3.6.9 64-bit ('py36': conda)","language":"python","name":"python369jvsc74a57bd047a2385e02337c9da7f7e3138ce6736e525632c23d10436a8fc6b989d8de9769"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0ee175a","executionInfo":{"status":"ok","timestamp":1623128577181,"user_tz":-330,"elapsed":2921,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}},"outputId":"7ce01bd1-336e-4431-c8fb-22dcdbbd3c52"},"source":["!pip install transformers\n"],"id":"b0ee175a","execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s6FiV0enfQJ4","executionInfo":{"status":"ok","timestamp":1623128581696,"user_tz":-330,"elapsed":4518,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}},"outputId":"ebbcc51d-8ded-43ce-fd5b-b406f10ce628"},"source":["import pandas as pd\n","import torch\n","from sklearn.model_selection import train_test_split\n","import transformers\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","!pip install transformers\n","from transformers import DistilBertModel, DistilBertTokenizer\n","from sklearn import metrics\n","from tqdm import tqdm\n","import numpy as np"],"id":"s6FiV0enfQJ4","execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4a493865","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623128583009,"user_tz":-330,"elapsed":1324,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}},"outputId":"9eec736b-28b5-4ac8-b1e6-539959909d07"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","train_data = pd.read_csv(\"/content/drive/MyDrive/yelp_review_full_csv/augmented_train_6500.csv\",header = None)\n","test_data = pd.read_csv(\"/content/drive/MyDrive/yelp_review_full_csv/test.csv\",header = None)\n","\n","#train_data = train_data.iloc[: , 1:]\n","train_data.columns = [2 , 0 , 1]\n","train_data[0][0] = 1\n","#train_data = train_data.iloc[1:]"],"id":"4a493865","execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PaRntwu3ggqL","executionInfo":{"status":"ok","timestamp":1623128583010,"user_tz":-330,"elapsed":25,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}},"outputId":"19c72d4d-206c-4e9a-c7cf-af9af57a3b10"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"PaRntwu3ggqL","execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5d12be20","executionInfo":{"status":"ok","timestamp":1623128583011,"user_tz":-330,"elapsed":23,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}},"outputId":"749b6c6f-d1ae-4e97-ee51-937195b9b9d4"},"source":["train_data.shape"],"id":"5d12be20","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(19471, 3)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"5B4sJy2WJ3Su","executionInfo":{"status":"ok","timestamp":1623128583011,"user_tz":-330,"elapsed":19,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}},"outputId":"686ac449-5b84-4d54-8088-f1de74f539a1"},"source":["train_data.head()"],"id":"5B4sJy2WJ3Su","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>5</td>\n","      <td>dr goldberg offers everything i look for in a ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>5</td>\n","      <td>dr goldberg offers everything see look for in ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.0</td>\n","      <td>5</td>\n","      <td>dr goldberg offers everything i look for in a ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3.0</td>\n","      <td>2</td>\n","      <td>unfortunately the frustration of being dr gold...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     2  0                                                  1\n","0  NaN  1                                                  1\n","1  0.0  5  dr goldberg offers everything i look for in a ...\n","2  1.0  5  dr goldberg offers everything see look for in ...\n","3  2.0  5  dr goldberg offers everything i look for in a ...\n","4  3.0  2  unfortunately the frustration of being dr gold..."]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6d32387","executionInfo":{"status":"ok","timestamp":1623128583012,"user_tz":-330,"elapsed":16,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}},"outputId":"16c0fa4c-2330-4dc3-fa06-5d3da7917e3d"},"source":["max(train_data[1].apply(len))"],"id":"d6d32387","execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5646"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"ed784797","executionInfo":{"status":"ok","timestamp":1623128583013,"user_tz":-330,"elapsed":13,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}}},"source":["#x_,x_train,y_,y_train = train_test_split(train_data[1],train_data[0],test_size=0.01)"],"id":"ed784797","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"25de7212","executionInfo":{"status":"ok","timestamp":1623128583013,"user_tz":-330,"elapsed":12,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}}},"source":[""],"id":"25de7212","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5c47a14e","executionInfo":{"status":"ok","timestamp":1623128585541,"user_tz":-330,"elapsed":2539,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}},"outputId":"715338d2-99c2-44d5-c096-24fce44f4283"},"source":["tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n","\n","model, pretrained_weights = (transformers.DistilBertModel, 'distilbert-base-uncased')\n","model = model.from_pretrained(pretrained_weights)\n","\n","#for child in model.children():\n","#  for param in child.parameters():\n","#      param.requires_grad = False"],"id":"5c47a14e","execution_count":9,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a556f82d","executionInfo":{"status":"ok","timestamp":1623128585543,"user_tz":-330,"elapsed":21,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}},"outputId":"b1a2f6d3-81f1-4d58-ce9d-be1ab877db5b"},"source":["print(' Original: ', train_data[1][1])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(train_data[1][1]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_data[1][1])))"],"id":"a556f82d","execution_count":10,"outputs":[{"output_type":"stream","text":[" Original:  dr goldberg offers everything i look for in a general practitioner hes nice and easy to talk to without being patronizing hes always decent on time in seeing his patients hes affiliated with a top notch hospital very along nyu which my parents angstrom have explained to me is very important in case something happens check and you need surgery and you can get pose referrals to see specialists without having to see him first really infirmary what more do you need im sitting here trying to think of more than any complaints i have about only him but im really drawing a blank\n","Tokenized:  ['dr', 'goldberg', 'offers', 'everything', 'i', 'look', 'for', 'in', 'a', 'general', 'practitioner', 'he', '##s', 'nice', 'and', 'easy', 'to', 'talk', 'to', 'without', 'being', 'patron', '##izing', 'he', '##s', 'always', 'decent', 'on', 'time', 'in', 'seeing', 'his', 'patients', 'he', '##s', 'affiliated', 'with', 'a', 'top', 'notch', 'hospital', 'very', 'along', 'nyu', 'which', 'my', 'parents', 'ang', '##strom', 'have', 'explained', 'to', 'me', 'is', 'very', 'important', 'in', 'case', 'something', 'happens', 'check', 'and', 'you', 'need', 'surgery', 'and', 'you', 'can', 'get', 'pose', 'refer', '##ral', '##s', 'to', 'see', 'specialists', 'without', 'having', 'to', 'see', 'him', 'first', 'really', 'infirmary', 'what', 'more', 'do', 'you', 'need', 'im', 'sitting', 'here', 'trying', 'to', 'think', 'of', 'more', 'than', 'any', 'complaints', 'i', 'have', 'about', 'only', 'him', 'but', 'im', 'really', 'drawing', 'a', 'blank']\n","Token IDs:  [2852, 18522, 4107, 2673, 1045, 2298, 2005, 1999, 1037, 2236, 18742, 2002, 2015, 3835, 1998, 3733, 2000, 2831, 2000, 2302, 2108, 9161, 6026, 2002, 2015, 2467, 11519, 2006, 2051, 1999, 3773, 2010, 5022, 2002, 2015, 6989, 2007, 1037, 2327, 18624, 2902, 2200, 2247, 27935, 2029, 2026, 3008, 17076, 15687, 2031, 4541, 2000, 2033, 2003, 2200, 2590, 1999, 2553, 2242, 6433, 4638, 1998, 2017, 2342, 5970, 1998, 2017, 2064, 2131, 13382, 6523, 7941, 2015, 2000, 2156, 15744, 2302, 2383, 2000, 2156, 2032, 2034, 2428, 23453, 2054, 2062, 2079, 2017, 2342, 10047, 3564, 2182, 2667, 2000, 2228, 1997, 2062, 2084, 2151, 10821, 1045, 2031, 2055, 2069, 2032, 2021, 10047, 2428, 5059, 1037, 8744]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e87aafb8","executionInfo":{"status":"ok","timestamp":1623128585544,"user_tz":-330,"elapsed":18,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}}},"source":["#x_token = x_train.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)[:300]))\n","\n","#padded = np.array([i + [0]*(300 -len(i)) for i in x_token.values])"],"id":"e87aafb8","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"4e607ddb","executionInfo":{"status":"ok","timestamp":1623128585545,"user_tz":-330,"elapsed":19,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}}},"source":["#attention_mask = np.where(padded != 0, 1, 0)\n"],"id":"4e607ddb","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6dfbe5b","executionInfo":{"status":"ok","timestamp":1623128585546,"user_tz":-330,"elapsed":19,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}}},"source":[""],"id":"d6dfbe5b","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"b5adfebf","executionInfo":{"status":"ok","timestamp":1623128585547,"user_tz":-330,"elapsed":20,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}}},"source":["class Yelp_Dataset(torch.utils.data.Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        \n","    def __getitem__(self, index):\n","        review = str(self.data[1][index])\n","        inputs = self.tokenizer.encode_plus(\n","            review,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            truncation = True,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'targets': torch.tensor(self.data[0][index], dtype=torch.long)\n","        }\n","        \n","    def __len__(self):\n","        return len(self.data)\n","    \n","train_dataset = Yelp_Dataset(train_data, tokenizer,200)\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True,drop_last = True)\n","\n","test_dataset = Yelp_Dataset(test_data[0:5000], tokenizer,200)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True,drop_last = True)"],"id":"b5adfebf","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3f675d60","executionInfo":{"status":"ok","timestamp":1623128588856,"user_tz":-330,"elapsed":3328,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}},"outputId":"1ddd226d-b3f4-4fb1-9f0e-a22696fd35d5"},"source":["class DistillBERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.distill_bert = model\n","        self.drop = torch.nn.Dropout(0.1)\n","        self.out = torch.nn.Linear(768, 5)\n","    \n","    def forward(self, ids, mask):\n","        distilbert_output = self.distill_bert(ids, mask)\n","        hidden_state = distilbert_output[0]  # (bs, seq_len, dim)\n","        pooled_output = hidden_state[:, 0]  # (bs, dim)\n","        output_1 = self.drop(pooled_output)\n","        output = self.out(output_1)\n","        return output\n","    \n","model = DistillBERTClass()\n","model.to(device)"],"id":"3f675d60","execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DistillBERTClass(\n","  (distill_bert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (drop): Dropout(p=0.1, inplace=False)\n","  (out): Linear(in_features=768, out_features=5, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"e703f603","executionInfo":{"status":"ok","timestamp":1623128588857,"user_tz":-330,"elapsed":7,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}}},"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"],"id":"e703f603","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"WQ7a2Xq9khl8","executionInfo":{"status":"ok","timestamp":1623128588857,"user_tz":-330,"elapsed":6,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}}},"source":["def accuracy(y_pred, y):\n","    _, predicted = torch.max(y_pred.data, 1)\n","    total = y.size(0)\n","    correct = (predicted == y).sum().item()\n","    return correct\n"],"id":"WQ7a2Xq9khl8","execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2cb0894e","executionInfo":{"status":"ok","timestamp":1623129782151,"user_tz":-330,"elapsed":1193299,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}},"outputId":"68301e89-15e4-4917-be3e-a68953a50722"},"source":["\n","for epoch in range(3):\n","    acc = 0\n","    for i,data in enumerate(train_loader, 0):\n","        optimizer.zero_grad()\n","        input_ids = data['ids'].to(device)\n","        attention_mask = data['mask'].to(device)\n","        labels = data['targets'].to(device)\n","        labels = labels - 1\n","        outputs = model(input_ids,attention_mask)\n","        loss = loss_fn(outputs,labels)\n","        loss.backward()\n","        optimizer.step()\n","        acc += accuracy(outputs,labels)\n","        if i%200 == 199:\n","            print('[%d, %d] accuracy: %.3f' %\n","                  (epoch + 1, i + 1, acc / ((i+1)*16)))\n","\n","\n","\n"],"id":"2cb0894e","execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["[1, 200] accuracy: 0.227\n","[1, 400] accuracy: 0.284\n","[1, 600] accuracy: 0.343\n","[1, 800] accuracy: 0.378\n","[1, 1000] accuracy: 0.407\n","[1, 1200] accuracy: 0.425\n","[2, 200] accuracy: 0.536\n","[2, 400] accuracy: 0.536\n","[2, 600] accuracy: 0.542\n","[2, 800] accuracy: 0.546\n","[2, 1000] accuracy: 0.553\n","[2, 1200] accuracy: 0.559\n","[3, 200] accuracy: 0.583\n","[3, 400] accuracy: 0.591\n","[3, 600] accuracy: 0.593\n","[3, 800] accuracy: 0.600\n","[3, 1000] accuracy: 0.605\n","[3, 1200] accuracy: 0.606\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9f735122","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623129822490,"user_tz":-330,"elapsed":40348,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}},"outputId":"bbbbfe7d-d176-4c38-c1e1-01949bbf66fa"},"source":["\n","acc = 0\n","with torch.no_grad():\n","    for i,data in enumerate(test_loader,0):\n","        model.eval()\n","        input_ids = data['ids'].to(device)\n","        attention_mask = data['mask'].to(device)\n","        labels = data['targets'].to(device)\n","        labels = labels - 1\n","        outputs = model(input_ids,attention_mask)\n","        acc += accuracy(outputs,labels)\n","print(i)\n","acc/((i+1)*16)"],"id":"9f735122","execution_count":18,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["311\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.5614983974358975"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"qIfELmG6fOAf","executionInfo":{"status":"ok","timestamp":1623129822491,"user_tz":-330,"elapsed":15,"user":{"displayName":"sachidanand vs","photoUrl":"","userId":"14290717920111096778"}}},"source":[""],"id":"qIfELmG6fOAf","execution_count":18,"outputs":[]}]}